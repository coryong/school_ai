{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "가중치의 초기값은 0으로 시작하고, 학습률은 0.1로 설정하겠습니다.\n",
        "\n",
        "퍼셉트론의 출력 함수는 입력과 가중치의 합이 0보다 크거나 같으면 1, 그렇지 않으면 0으로 정의하겠습니다.\n",
        "\n",
        "가중치 업데이트는 아래와 같은 공식에 따라 진행됩니다: w = w + η * (d - y) * x\n"
      ],
      "metadata": {
        "id": "DnC9RsSL3VcA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "921NqDCV3fWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 용어를 설명하라\n",
        "\n",
        "\n",
        "(1) 하이퍼파라미터(Hyperparameter):\n",
        "하이퍼파라미터란 머신러닝 모델의 구조나 학습 알고리즘에 영향을 주는 매개변수를 의미합니다. 이러한 매개변수는 모델 학습 전에 사람이 수동으로 설정해야 하며, 학습 과정 중에는 자동으로 조정되지 않습니다. 예를 들어, 신경망 모델에서 은닉층의 수, 각 층의 뉴런 개수, 학습률 등이 하이퍼파라미터입니다. 이러한 하이퍼파라미터를 조정하면 모델의 성능과 학습 속도에 영향을 줄 수 있습니다.\n",
        "\n",
        "(2) 기울기 소실(Vanishing Gradient):\n",
        "기울기 소실은 신경망 학습 과정에서 발생하는 문제로, 역전파 알고리즘을 사용하여 신경망을 학습시킬 때 일어납니다. 신경망의 깊이가 깊어질수록, 역전파 알고리즘에 의해 그래디언트(기울기)가 출력층에서 입력층으로 전달되면서 작아지는 현상입니다. 이러한 작은 그래디언트는 가중치 업데이트에 거의 영향을 주지 않아 신경망이 제대로 학습되지 않고, 성능이 좋지 않게 될 수 있습니다.\n",
        "\n",
        "(3) 배치 정규화(Batch Normalization):\n",
        "배치 정규화는 딥러닝 모델에서 사용되는 기법 중 하나로, 학습 과정 동안 각 미니배치의 입력 데이터를 정규화하는 과정입니다. 배치 정규화는 신경망의 각 층에서 활성화 값을 조정하여 그래디언트의 사라지는 문제를 완화하고, 학습 속도를 향상시키는 효과가 있습니다. 또한, 가중치 초기화에 대한 의존성을 줄이고, 모델의 일반화 성능을 향상시킵니다.\n",
        "\n",
        "(4) 옵티마이저(Optimizer):\n",
        "옵티마이저는 머신러닝 모델의 학습 과정에서 손실 함수를 최적화하는 방법을 결정하는 알고리즘입니다. 옵티마이저는 모델의 가중치와 편향을 업데이트하여 손실 함수를 최소화하도록 합니다. 예를 들어, 경사 하강법(Gradient Descent) 알고리즘은 옵티마이저의 일종으로, 그래디언트를 사용하여 손실 함수를 최소화하는 방향으로 모델을 업데이트합니다. 다른 옵티마이저에는 모멘텀 최적화(Momentum Optimization), 아담(Adam) 등이 있습니다.\n",
        "\n",
        "(5) 드롭아웃(Dropout):\n",
        "드롭아웃은 신경망에서 사용되는 정규화 기법 중 하나로, 학습 과정 중에 랜덤하게 일부 뉴런을 제거하고, 제거된 뉴런을 포함한 신경망으로 학습을 진행하는 방법입니다. 이를 통해 모델이 특정 뉴런에 지나치게 의존하지 않도록 하여 과적합을 방지하고, 모델의 일반화 능력을 향상시킬 수 있습니다.\n",
        "\n",
        "(6) 합성곱(Convolution):\n",
        "합성곱은 신경망에서 이미지 처리와 같은 공간 정보를 가진 데이터를 처리하기 위한 연산입니다. 합성곱은 커널(필터)과 입력 데이터의 원소간의 곱셈과 합을 통해 새로운 특성 맵을 생성합니다. 이를 통해 이미지의 공간적인 패턴을 감지하거나 특성을 추출하는데 사용됩니다. 합성곱 연산은 합성곱 신경망(Convolutional Neural Network, CNN)의 주요 구성 요소로 활용되며, 이미지 분류, 객체 검출 등에 널리 사용됩니다.\n",
        "\n",
        "(7) 전이 학습(Transfer Learning):\n",
        "전이 학습은 한 도메인에서 학습된 모델의 지식을 다른 도메인의 학습에 활용하는 방법입니다. 전이 학습은 기존에 큰 규모의 데이터셋에서 학습된 모델을 가져와서 새로운 작업에 활용하거나, 비슷한 도메인에서 학습된 모델의 일부를 재사용하여 학습 속도와 성능을 개선하는 데 사용됩니다. 이를 통해 적은 데이터로도 효과적인 모델을 학습할 수 있으며, 실제 응용 분야에서 많이 활용되는 기법입니다.\n",
        "\n",
        "(8) 특이값 분해(Singular Value Decomposition, SVD):\n",
        "특이값 분해는 선형 대수학에서 사용되는 기법으로, 행렬을 세 개의 행렬의 곱으로 분해하는 방법입니다. 주어진 행렬을 세 가지 행렬의 곱으로 분해함으로써, 행렬의 특성을 파악하고 정보를 추출할 수 있습니다. 특이값 분해는 차원 축소, 행렬의 랭크 결정, 행렬의 역행렬 계산 등 다양한 분야에서 사용됩니다.\n",
        "\n",
        "(9) 매니폴드(Manifold):\n",
        "매니폴드는 고차원 공간에서의 저차원 부분 공간을 나타내는 수학적인 개념입니다. 고차원 데이터는 저차원 매니폴드 상에 분포되어 있을 때, 이를 이해하고 처리하는 데 유용합니다. 매니폴드 학습은 고차원 데이터를 저차원의 매니폴드 공간으로 변환하여 데이터의 차원을 축소하고, 주요한 정보를 추출하는 방법입니다. 이를 통해 데이터 시각화, 차원 축소, 패턴 인식 등에 활용됩니다.\n",
        "\n",
        "(10) 잠재 표현(Latent Representation):\n",
        "잠재 표현은 머신러닝 모델에서 입력 데이터를 나타내는 고차원 벡터로, 데이터의 중요한 특성을 포착하고 나타냅니다. 이러한 잠재 표현은 데이터의 특성을 나타내는 요소들로 구성되며, 데이터를 표현하거나 변환하는 데 사용됩니다. 잠재 표현은 차원 축소, 군집화, 생성 모델 등 다양한 응용 분야에서 활용됩니다."
      ],
      "metadata": {
        "id": "ErvM_kFiAAXe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yjRPPTMHAFT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Forward Propagation (순전파):\n",
        "- 입력층에서 은닉층으로의 전달: 입력값과 가중치를 곱하고, 활성화 함수(sigmoid)를 적용하여 은닉층의 출력을 계산합니다.\n",
        "- 은닉층에서 출력층으로의 전달: 은닉층의 출력과 은닉층과 출력층 사이의 가중치를 곱하고, 활성화 함수(sigmoid)를 적용하여 출력층의 출력을 계산합니다.\n",
        "\n",
        "\n",
        "2. 계산된 출력과 실제 출력을 비교하여 오차를 계산합니다.\n",
        "\n",
        "\n",
        "3. Backward Propagation (오류역전파):\n",
        "- 출력층에서 은닉층으로의 역전파:\n",
        "  - 출력층의 오차를 계산하여 은닉층과 출력층 사이의 가중치(w)를 수정합니다.\n",
        "  - 은닉층의 출력과 가중치 w의 변화율을 곱하여 은닉층의 오차를 계산합니다.\n",
        "- 은닉층에서 입력층으로의 역전파:\n",
        "  - 은닉층의 오차를 계산하여 입력층과 은닉층 사이의 가중치(u1, u2)를 수정합니다.\n",
        "\n",
        "\n",
        "4. 가중치 수정:\n",
        "- 계산된 오차를 이용하여 가중치를 수정합니다. 일반적으로 경사하강법(Gradient Descent)을 사용하여 가중치를 업데이트합니다.\n",
        "- 은닉층과 출력층 사이의 가중치 w를 수정하고, 입력층과 은닉층 사이의 가중치 u1, u2를 수정합니다.\n",
        "\n",
        "\n",
        "5. 위 과정을 반복하면서 가중치를 업데이트하고, 오차를 최소화하는 방향으로 학습을 진행합니다. 학습을 여러 번 반복하면 네트워크가 데이터에 대해 더 나은 예측을 할 수 있도록 학습됩니다."
      ],
      "metadata": {
        "id": "gjxqHcNmC7kY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PwGH3vD3EZQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Fashion-MNIST 데이터셋 로드\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# 데이터를 1차원 벡터로 변환\n",
        "train_images = train_images.reshape(-1, 28*28)\n",
        "test_images = test_images.reshape(-1, 28*28)\n",
        "\n",
        "# MLP 모델 구성\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(256, activation='relu', input_shape=(28*28,)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=50, batch_size=128, validation_split=0.3)\n",
        "\n",
        "# 테스트 데이터로 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('테스트 정확도:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93rl20NzK3hN",
        "outputId": "a8cc0993-1f91-4fe0-c4c7-59dd9d82a35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329/329 [==============================] - 7s 5ms/step - loss: 0.7010 - accuracy: 0.7544 - val_loss: 0.4576 - val_accuracy: 0.8306\n",
            "Epoch 2/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.4597 - accuracy: 0.8377 - val_loss: 0.3890 - val_accuracy: 0.8556\n",
            "Epoch 3/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.4189 - accuracy: 0.8498 - val_loss: 0.3667 - val_accuracy: 0.8678\n",
            "Epoch 4/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.3882 - accuracy: 0.8600 - val_loss: 0.3651 - val_accuracy: 0.8669\n",
            "Epoch 5/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.3700 - accuracy: 0.8663 - val_loss: 0.3535 - val_accuracy: 0.8716\n",
            "Epoch 6/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.3534 - accuracy: 0.8722 - val_loss: 0.3457 - val_accuracy: 0.8739\n",
            "Epoch 7/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.8764 - val_loss: 0.3451 - val_accuracy: 0.8749\n",
            "Epoch 8/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.8787 - val_loss: 0.3372 - val_accuracy: 0.8775\n",
            "Epoch 9/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.3185 - accuracy: 0.8833 - val_loss: 0.3665 - val_accuracy: 0.8703\n",
            "Epoch 10/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.3091 - accuracy: 0.8873 - val_loss: 0.3190 - val_accuracy: 0.8885\n",
            "Epoch 11/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.3026 - accuracy: 0.8883 - val_loss: 0.3399 - val_accuracy: 0.8769\n",
            "Epoch 12/50\n",
            "329/329 [==============================] - 3s 10ms/step - loss: 0.2944 - accuracy: 0.8911 - val_loss: 0.3167 - val_accuracy: 0.8863\n",
            "Epoch 13/50\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.2868 - accuracy: 0.8933 - val_loss: 0.3201 - val_accuracy: 0.8867\n",
            "Epoch 14/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2831 - accuracy: 0.8963 - val_loss: 0.3131 - val_accuracy: 0.8863\n",
            "Epoch 15/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2731 - accuracy: 0.8993 - val_loss: 0.3234 - val_accuracy: 0.8860\n",
            "Epoch 16/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2711 - accuracy: 0.8970 - val_loss: 0.3182 - val_accuracy: 0.8864\n",
            "Epoch 17/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2685 - accuracy: 0.8995 - val_loss: 0.3126 - val_accuracy: 0.8917\n",
            "Epoch 18/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2633 - accuracy: 0.9029 - val_loss: 0.3181 - val_accuracy: 0.8888\n",
            "Epoch 19/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2586 - accuracy: 0.9035 - val_loss: 0.3041 - val_accuracy: 0.8918\n",
            "Epoch 20/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.2477 - accuracy: 0.9074 - val_loss: 0.3217 - val_accuracy: 0.8882\n",
            "Epoch 21/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2476 - accuracy: 0.9083 - val_loss: 0.3135 - val_accuracy: 0.8907\n",
            "Epoch 22/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2449 - accuracy: 0.9085 - val_loss: 0.3203 - val_accuracy: 0.8913\n",
            "Epoch 23/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2384 - accuracy: 0.9106 - val_loss: 0.3211 - val_accuracy: 0.8884\n",
            "Epoch 24/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2350 - accuracy: 0.9116 - val_loss: 0.3132 - val_accuracy: 0.8926\n",
            "Epoch 25/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2336 - accuracy: 0.9106 - val_loss: 0.3154 - val_accuracy: 0.8939\n",
            "Epoch 26/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2287 - accuracy: 0.9135 - val_loss: 0.3131 - val_accuracy: 0.8938\n",
            "Epoch 27/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2270 - accuracy: 0.9142 - val_loss: 0.3246 - val_accuracy: 0.8877\n",
            "Epoch 28/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.2247 - accuracy: 0.9138 - val_loss: 0.3142 - val_accuracy: 0.8936\n",
            "Epoch 29/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2228 - accuracy: 0.9158 - val_loss: 0.3167 - val_accuracy: 0.8975\n",
            "Epoch 30/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2146 - accuracy: 0.9202 - val_loss: 0.3203 - val_accuracy: 0.8947\n",
            "Epoch 31/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9197 - val_loss: 0.3310 - val_accuracy: 0.8904\n",
            "Epoch 32/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9205 - val_loss: 0.3183 - val_accuracy: 0.8987\n",
            "Epoch 33/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9214 - val_loss: 0.3271 - val_accuracy: 0.8898\n",
            "Epoch 34/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9220 - val_loss: 0.3315 - val_accuracy: 0.8918\n",
            "Epoch 35/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9230 - val_loss: 0.3472 - val_accuracy: 0.8924\n",
            "Epoch 36/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2062 - accuracy: 0.9234 - val_loss: 0.3360 - val_accuracy: 0.8951\n",
            "Epoch 37/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2003 - accuracy: 0.9239 - val_loss: 0.3371 - val_accuracy: 0.8931\n",
            "Epoch 38/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9231 - val_loss: 0.3211 - val_accuracy: 0.8973\n",
            "Epoch 39/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1924 - accuracy: 0.9275 - val_loss: 0.3301 - val_accuracy: 0.8971\n",
            "Epoch 40/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1967 - accuracy: 0.9255 - val_loss: 0.3238 - val_accuracy: 0.8969\n",
            "Epoch 41/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1886 - accuracy: 0.9282 - val_loss: 0.3286 - val_accuracy: 0.8972\n",
            "Epoch 42/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1846 - accuracy: 0.9275 - val_loss: 0.3378 - val_accuracy: 0.8956\n",
            "Epoch 43/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1876 - accuracy: 0.9290 - val_loss: 0.3319 - val_accuracy: 0.8967\n",
            "Epoch 44/50\n",
            "329/329 [==============================] - 1s 5ms/step - loss: 0.1880 - accuracy: 0.9283 - val_loss: 0.3328 - val_accuracy: 0.8941\n",
            "Epoch 45/50\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.1831 - accuracy: 0.9301 - val_loss: 0.3641 - val_accuracy: 0.8911\n",
            "Epoch 46/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1771 - accuracy: 0.9318 - val_loss: 0.3502 - val_accuracy: 0.8965\n",
            "Epoch 47/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1774 - accuracy: 0.9314 - val_loss: 0.3451 - val_accuracy: 0.8966\n",
            "Epoch 48/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.9338 - val_loss: 0.3421 - val_accuracy: 0.8962\n",
            "Epoch 49/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1750 - accuracy: 0.9327 - val_loss: 0.3511 - val_accuracy: 0.8991\n",
            "Epoch 50/50\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1736 - accuracy: 0.9342 - val_loss: 0.3492 - val_accuracy: 0.9001\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3776 - accuracy: 0.8922\n",
            "테스트 정확도: 0.8921999931335449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QUOyHaMv9n",
        "outputId": "ed1ecdff-8265-4a20-f65a-e8b0c6692c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 218,058\n",
            "Trainable params: 218,058\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 번째 은닉층:\n",
        "  - 입력 크기: 784\n",
        "  - 노드 수: 256\n",
        "  - 파라미터 개수 = (입력 크기 + 1) * 노드 수 = (784 + 1) * 256 = 200,960\n",
        "\n",
        "\n",
        "두 번째 은닉층:\n",
        "  - 입력 크기: 256\n",
        "  - 노드 수: 64\n",
        "  - 파라미터 개수 = (입력 크기 + 1) * 노드 수 = (256 + 1) * 64 = 16,448\n",
        "\n",
        "\n",
        "출력층:\n",
        "  - 입력 크기: 64\n",
        "  - 노드 수: 10\n",
        "  - 파라미터 개수 = (입력 크기 + 1) * 노드 수 = (64 + 1) * 10 = 650"
      ],
      "metadata": {
        "id": "eeGO-YOINyQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Fashion-MNIST 데이터셋 로드\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# CNN 모델 구성\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), strides=2, padding='same', activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 데이터 차원 변경 (1차원을 3차원으로)\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=50, batch_size=128, validation_split=0.3)\n",
        "\n",
        "# 테스트 데이터로 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('테스트 정확도:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMbMVY4PNxvO",
        "outputId": "6eede034-fe02-4947-a1cf-a94d08801281"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "329/329 [==============================] - 13s 7ms/step - loss: 0.8504 - accuracy: 0.6943 - val_loss: 0.5153 - val_accuracy: 0.8055\n",
            "Epoch 2/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.5037 - accuracy: 0.8193 - val_loss: 0.3925 - val_accuracy: 0.8589\n",
            "Epoch 3/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.4111 - accuracy: 0.8540 - val_loss: 0.3497 - val_accuracy: 0.8723\n",
            "Epoch 4/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.3612 - accuracy: 0.8738 - val_loss: 0.3251 - val_accuracy: 0.8836\n",
            "Epoch 5/50\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.3314 - accuracy: 0.8845 - val_loss: 0.3451 - val_accuracy: 0.8726\n",
            "Epoch 6/50\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.3074 - accuracy: 0.8909 - val_loss: 0.3077 - val_accuracy: 0.8892\n",
            "Epoch 7/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2907 - accuracy: 0.8976 - val_loss: 0.2808 - val_accuracy: 0.8978\n",
            "Epoch 8/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2746 - accuracy: 0.9019 - val_loss: 0.2796 - val_accuracy: 0.8982\n",
            "Epoch 9/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2637 - accuracy: 0.9040 - val_loss: 0.2955 - val_accuracy: 0.8917\n",
            "Epoch 10/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2513 - accuracy: 0.9091 - val_loss: 0.2671 - val_accuracy: 0.9034\n",
            "Epoch 11/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.2390 - accuracy: 0.9135 - val_loss: 0.2642 - val_accuracy: 0.9051\n",
            "Epoch 12/50\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.2312 - accuracy: 0.9174 - val_loss: 0.2728 - val_accuracy: 0.9022\n",
            "Epoch 13/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.2211 - accuracy: 0.9213 - val_loss: 0.2638 - val_accuracy: 0.9066\n",
            "Epoch 14/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2166 - accuracy: 0.9207 - val_loss: 0.2665 - val_accuracy: 0.9057\n",
            "Epoch 15/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.2031 - accuracy: 0.9250 - val_loss: 0.2771 - val_accuracy: 0.9042\n",
            "Epoch 16/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1963 - accuracy: 0.9291 - val_loss: 0.2649 - val_accuracy: 0.9056\n",
            "Epoch 17/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.1918 - accuracy: 0.9294 - val_loss: 0.2660 - val_accuracy: 0.9075\n",
            "Epoch 18/50\n",
            "329/329 [==============================] - 3s 8ms/step - loss: 0.1805 - accuracy: 0.9338 - val_loss: 0.2656 - val_accuracy: 0.9080\n",
            "Epoch 19/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1766 - accuracy: 0.9349 - val_loss: 0.2675 - val_accuracy: 0.9087\n",
            "Epoch 20/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1686 - accuracy: 0.9382 - val_loss: 0.2780 - val_accuracy: 0.9053\n",
            "Epoch 21/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.1630 - accuracy: 0.9395 - val_loss: 0.2747 - val_accuracy: 0.9084\n",
            "Epoch 22/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1599 - accuracy: 0.9414 - val_loss: 0.2714 - val_accuracy: 0.9104\n",
            "Epoch 23/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1495 - accuracy: 0.9435 - val_loss: 0.2825 - val_accuracy: 0.9074\n",
            "Epoch 24/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.1421 - accuracy: 0.9480 - val_loss: 0.2870 - val_accuracy: 0.9121\n",
            "Epoch 25/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.1396 - accuracy: 0.9488 - val_loss: 0.3218 - val_accuracy: 0.9028\n",
            "Epoch 26/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1326 - accuracy: 0.9510 - val_loss: 0.3022 - val_accuracy: 0.9094\n",
            "Epoch 27/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.1280 - accuracy: 0.9514 - val_loss: 0.3138 - val_accuracy: 0.9081\n",
            "Epoch 28/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1225 - accuracy: 0.9545 - val_loss: 0.3255 - val_accuracy: 0.9091\n",
            "Epoch 29/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1206 - accuracy: 0.9549 - val_loss: 0.3135 - val_accuracy: 0.9091\n",
            "Epoch 30/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1142 - accuracy: 0.9560 - val_loss: 0.3290 - val_accuracy: 0.9084\n",
            "Epoch 31/50\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.1046 - accuracy: 0.9600 - val_loss: 0.3311 - val_accuracy: 0.9091\n",
            "Epoch 32/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1096 - accuracy: 0.9585 - val_loss: 0.3376 - val_accuracy: 0.9093\n",
            "Epoch 33/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1029 - accuracy: 0.9596 - val_loss: 0.3603 - val_accuracy: 0.9099\n",
            "Epoch 34/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.1000 - accuracy: 0.9625 - val_loss: 0.3485 - val_accuracy: 0.9087\n",
            "Epoch 35/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0973 - accuracy: 0.9639 - val_loss: 0.3537 - val_accuracy: 0.9069\n",
            "Epoch 36/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.0900 - accuracy: 0.9661 - val_loss: 0.3584 - val_accuracy: 0.9091\n",
            "Epoch 37/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.0920 - accuracy: 0.9643 - val_loss: 0.3667 - val_accuracy: 0.9103\n",
            "Epoch 38/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.0851 - accuracy: 0.9676 - val_loss: 0.3771 - val_accuracy: 0.9112\n",
            "Epoch 39/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0794 - accuracy: 0.9702 - val_loss: 0.3994 - val_accuracy: 0.9063\n",
            "Epoch 40/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0851 - accuracy: 0.9681 - val_loss: 0.3916 - val_accuracy: 0.9064\n",
            "Epoch 41/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0786 - accuracy: 0.9697 - val_loss: 0.3943 - val_accuracy: 0.9076\n",
            "Epoch 42/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0759 - accuracy: 0.9709 - val_loss: 0.4057 - val_accuracy: 0.9072\n",
            "Epoch 43/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0713 - accuracy: 0.9730 - val_loss: 0.4097 - val_accuracy: 0.9082\n",
            "Epoch 44/50\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 0.0713 - accuracy: 0.9728 - val_loss: 0.4124 - val_accuracy: 0.9067\n",
            "Epoch 45/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.0735 - accuracy: 0.9730 - val_loss: 0.4557 - val_accuracy: 0.9028\n",
            "Epoch 46/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0709 - accuracy: 0.9739 - val_loss: 0.4433 - val_accuracy: 0.9049\n",
            "Epoch 47/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0601 - accuracy: 0.9776 - val_loss: 0.4502 - val_accuracy: 0.9050\n",
            "Epoch 48/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0639 - accuracy: 0.9756 - val_loss: 0.4399 - val_accuracy: 0.9096\n",
            "Epoch 49/50\n",
            "329/329 [==============================] - 2s 5ms/step - loss: 0.0591 - accuracy: 0.9782 - val_loss: 0.4572 - val_accuracy: 0.9088\n",
            "Epoch 50/50\n",
            "329/329 [==============================] - 2s 6ms/step - loss: 0.0623 - accuracy: 0.9762 - val_loss: 0.4384 - val_accuracy: 0.9067\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.9005\n",
            "테스트 정확도: 0.9004999995231628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frkcHCZ6Q2rj",
        "outputId": "3cbbef59-0cd0-4a6c-934e-dfd2a0a33908"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 7, 7, 64)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,458\n",
            "Trainable params: 120,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 번째 Conv2D 레이어\n",
        "- 입력 크기: 28x28x1\n",
        "- 필터 크기: 3x3\n",
        "- 필터 개수: 64\n",
        "- 스트라이드: 2\n",
        "- 패딩: \"same\"\n",
        "- 파라미터 수: (3x3x1 + 1) x 64 = 640\n",
        "\n",
        "첫 번째 MaxPooling2D 레이어:\n",
        "- 풀링 크기: 2x2\n",
        "- 파라미터 수: 0 (풀링 레이어는 학습되는 파라미터가 없음)\n",
        "\n",
        "두 번째 Conv2D 레이어:\n",
        "- 입력 크기: 14x14x64 (이전 레이어에서 풀링으로 인해 크기가 줄어듦)\n",
        "- 필터 크기: 3x3\n",
        "- 필터 개수: 64\n",
        "- 스트라이드: 2\n",
        "- 패딩: \"same\"\n",
        "- 파라미터 수: (3x3x64 + 1) x 64 = 36928\n",
        "\n",
        "두 번째 MaxPooling2D 레이어:\n",
        "- 풀링 크기: 2x2\n",
        "- 파라미터 수: 0 (풀링 레이어는 학습되는 파라미터가 없음)\n",
        "\n",
        "총 CNN 파라미터 수: 640 + 0 + 36928 + 0 = 37568\n",
        "\n",
        "따라서, 위 (3) 모델의 CNN 계층은 총 37,568개의 파라미터를 가지고 있습니다"
      ],
      "metadata": {
        "id": "dMMLC4EBRCMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_W3XLnG2RPi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) 차원축소는 차원의 저주로 인해 발생하는 몇 가지 문제점을 해소할 수 있습니다. 차원의 저주란, 고차원 공간에서 데이터 포인트들이 희소하게 분포하여 데이터 분석이 어렵고 비효율적이라는 현상을 의미합니다. 차원이 증가할수록 데이터 포인트 사이의 거리가 멀어지고, 데이터의 분포를 잘 표현하기 위해 필요한 데이터 양도 기하급수적으로 증가합니다.\n",
        "\n",
        "차원축소는 고차원 데이터를 저차원으로 변환함으로써 이러한 문제를 해결할 수 있습니다. 저차원으로 변환된 데이터는 데이터의 분포를 더 잘 표현하고, 데이터 간의 거리가 더 가까워져 유사한 패턴이나 관계를 더 잘 파악할 수 있게 됩니다. 이를 통해 데이터 분석이 간편해지고, 예측 모델의 성능 향상이 기대됩니다.\n",
        "\n",
        "(2) 차원 축소 과정에서 감수해야 하는 단점은 다음과 같습니다.\n",
        "- 정보 손실: 차원 축소는 원래 데이터의 차원을 줄이기 때문에 일부 정보가 손실될 수 있습니다. 이는 원래 데이터의 특징이나 변동성을 완벽하게 보존하지 못하고 압축된 형태로 표현됨을 의미합니다.\n",
        "\n",
        "- 해석의 어려움: 저차원으로 축소된 데이터는 원래 데이터보다 해석하기 어려울 수 있습니다. 축소된 차원은 원래 데이터의 특성을 추상화하고 합성한 형태이기 때문에, 이를 해석하고 이해하기가 어려울 수 있습니다.\n",
        "\n",
        "- 계산 비용: 일부 차원 축소 알고리즘은 계산적으로 비용이 많이 들 수 있습니다. 특히, 대규모 데이터셋이나 고차원 데이터의 경우에는 계산 비용이 급증할 수 있습니다.\n",
        "\n",
        "(3) autoencoder를 이용한 차원축소와 주성분 분석(PCA)을 통한 차원 축소의 차이점은 다음과 같습니다:\n",
        "\n",
        "- 방법론: autoencoder는 신경망 기반의 비지도학습 방법으로, 입력 데이터를 잠재 공간으로 인코딩하고, 다시 재구성하는 과정을 통해 차원 축소를 수행합니다. 반면에 PCA는 선형 변환을 사용하여 데이터의 분산을 최대로 보존하는 저차원 표현을 찾는 방법입니다.\n",
        "- 유연성: autoencoder는 비선형 변환을 통해 복잡한 데이터 구조를 학습할 수 있으므로, 비선형 관계를 갖는 데이터에 대해서도 잘 동작할 수 있습니다. 반면에 PCA는 선형 변환만을 사용하므로, 비선형 구조를 잘 반영하지 못할 수 있습니다.\n",
        "- 지도/비지도 학습: autoencoder는 비지도학습 방법이므로, 입력 데이터에 대한 레이블 정보를 사용하지 않습니다. 반면에 PCA는 주로 비지도학습으로 사용되지만, 필요에 따라 입력 데이터의 레이블 정보를 활용하여 데이터 분산을 최대화하는 방향으로 변환을 수행할 수도 있습니다."
      ],
      "metadata": {
        "id": "Aohz9YV0RboI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fv3LoRB6Rkll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning과 deep learning은 인공지능 분야에서 주요한 개념이지만, 그들 간에는 몇 가지 중요한 차이점이 있습니다. 아래에서는 이러한 차이점을 상세히 설명하겠습니다.\n",
        "\n",
        "1. 구조와 아키텍처:\n",
        "\n",
        "- Machine learning: Machine learning은 데이터를 학습하고 패턴을 발견하기 위해 통계적 모델을 사용합니다. 주로 특성 추출, 모델 선택 및 하이퍼파라미터 조정과 같은 전처리 과정을 포함합니다. 전통적인 기계 학습 방법에는 회귀, 분류, 군집화 및 차원 축소와 같은 다양한 알고리즘이 포함됩니다.\n",
        "- Deep learning: Deep learning은 인공신경망(artificial neural network)이라고도 불리는 계층적인 구조를 사용하여 패턴을 학습합니다. Deep learning은 데이터의 표현을 자동으로 학습하며, 복잡한 비선형 관계를 모델링할 수 있습니다. Deep learning은 다양한 은닉층(hidden layer)으로 구성된 신경망을 사용하며, 주로 이미지, 음성 및 자연어 처리와 같은 고수준의 작업에 사용됩니다.\n",
        "\n",
        "2. 데이터 요구 사항:\n",
        "\n",
        "- Machine learning: Machine learning은 상대적으로 적은 양의 데이터로도 좋은 결과를 얻을 수 있습니다. 데이터의 특성을 수동으로 추출해야 할 수도 있지만, 데이터의 양이 제한적인 경우에도 일반적으로 사용됩니다.\n",
        "- Deep learning: Deep learning은 대규모의 데이터셋이 필요합니다. Deep learning 모델은 대용량의 데이터를 사용하여 표현력과 일반화 능력을 향상시키는 경향이 있습니다. 따라서 Deep learning은 대규모 데이터셋을 사용할 수 있는 경우에 가장 효과적입니다.\n",
        "\n",
        "3. 특성 추출:\n",
        "\n",
        "- Machine learning: Machine learning에서는 특성 추출(feature extraction)과 선택이 중요한 단계입니다. 전통적인 기계 학습에서는 도메인 전문가가 특성을 정의하고 추출하는 과정이 필요합니다. 이러한 특성은 일반적으로 데이터의 주요 속성을 나타내는 데 도움이 됩니다.\n",
        "- Deep learning: Deep learning은 데이터로부터 자동으로 특성을 학습합니다. Deep learning 모델은 입력 데이터에서 특징을 추출하는 과정을 내부적으로 처리합니다. 이는 데이터에서 가장 유용한 특징을 학습하고 표현을 자동으로 학습함으로써 많은 특성 공학 단계를 제거합니다.\n",
        "\n",
        "4. 계산 리소스:\n",
        "\n",
        "- Machine learning: Machine learning 모델은 일반적으로 상대적으로 적은 계산 리소스를 요구합니다. 대부분의 기계 학습 알고리즘은 비교적 간단하고 계산적으로 경제적입니다.\n",
        "- Deep learning: Deep learning은 많은 계산 리소스를 필요로 합니다. Deep learning 모델은 많은 수의 파라미터와 계산을 필요로 하기 때문에 고성능 하드웨어(예: GPU 또는 TPU)를 사용하여 훈련과 추론을 수행하는 것이 일반적입니다.\n",
        "\n",
        "5. 활용 분야:\n",
        "\n",
        "- Machine learning: Machine learning은 다양한 분야에서 사용됩니다. 예를 들어, 주가 예측, 이메일 스팸 필터링, 고객 세분화, 의료 진단, 추천 시스템 등에 적용될 수 있습니다.\n",
        "- Deep learning: Deep learning은 주로 이미지 분류, 객체 탐지, 음성 인식, 자연어 처리, 기계 번역 등의 고수준 작업에 사용됩니다. 특히 컴퓨터 비전과 음성 처리 분야에서 많은 성과를 내고 있습니다.\n",
        "이러한 차이점을 통해 Machine learning과 Deep learning은 서로 보완적인 개념으로 이해될 수 있습니다. Machine learning은 비교적 간단하고 데이터 요구 사항이 적은 경우에 유용하며, Deep learning은 대규모 데이터셋과 계산 리소스가 있는 경우에 더 나은 성능을 발휘합니다."
      ],
      "metadata": {
        "id": "QbTlr4y-SQnz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CCV9AhMPSdfN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}